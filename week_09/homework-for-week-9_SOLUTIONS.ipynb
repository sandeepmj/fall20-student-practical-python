{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework for Week 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xAOVdlw0Cwm"
   },
   "source": [
    "## Homework 1 - Find the Tables\n",
    "\n",
    "In the document called <a href=\"https://www.dropbox.com/s/af5eob7htijsb81/dod.pdf?dl=0\">dod.pdf</a>\n",
    "\n",
    "1. Capture the table on page 4-3 in Chapter 4 that gives the FY 2020 Defense Budget for Major Weapons Programs. (Figure 4.1) and download it as a CSV.\n",
    "\n",
    "2. Capture the table on page 4-9 in Chapter 4 that gives the FY 2020 Defense Budget for Nuclear Modernization (figure 4.3) and download it as a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's pull in our DOD pdf \n",
    "path_01 = \"dod.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## capture both tables using range of numbers (remember NO spaces in specifying numbers)\n",
    "dod_table_1 = tabula.read_pdf(path_01, pages = \"48,54\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let print out Figure 4.1\n",
    "dod_table_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let print out Figure 4.3\n",
    "dod_table_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn figure 4.1 into pandas dataframe\n",
    "df = pd.DataFrame(dod_table_1[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export figure 4.1 and download as CSV file\n",
    "filename = \"major-weapons-programs.csv\"\n",
    "df.to_csv(filename, encoding='utf-8', index=False)\n",
    "files.download(filename) ## colab command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn figure 4.3 into pandas dataframe\n",
    "df2 = pd.DataFrame(dod_table_1[1])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export figure 4.3 and download as CSV file\n",
    "filename = \"nuclear-modernization.csv\"\n",
    "df2.to_csv(filename, encoding='utf-8', index=False)\n",
    "files.download(filename) ## colab command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bwcv3o39z82D"
   },
   "source": [
    "## Homework 2 - Multi-State FUDS \n",
    "\n",
    "- Access <a href=\"https://www.dropbox.com/s/mjf3k5x1cjeqnc0/homework_fuds.zip?dl=0\">homework_fuds.zip</a>.\n",
    "\n",
    "- Manually unzip only ```homework_fuds.zip```. It contains three additional zip files. **DO NOT** manually unzip them.\n",
    "\n",
    "- Write a script that opens each zip folder, finds only the pdf file it contains and grab all the tables...\n",
    "\n",
    "- The final product should be a single csv file that contains the FUDS data for all three states (Alaska, New York and West Virginia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import unzipper\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import glob\n",
    "import os  ## allows you to navigate, create, delete folders\n",
    "from pathlib import Path ## allows to create paths to files and folders\n",
    "import tabula\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['homework_fuds/ny_fuds.zip', 'homework_fuds/west_virginia_fuds.zip']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfolders = sorted(glob.glob('homework_fuds/*.zip'))\n",
    "myfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found this image: ny_fuds/FUDS_NY.pdf\n",
      "Found this image: __MACOSX/ny_fuds/._FUDS_NY.pdf\n",
      "Found this image: west_virginia_fuds/FUDS_Inventory_WestVirginia.pdf\n",
      "Found this image: __MACOSX/west_virginia_fuds/._FUDS_Inventory_WestVirginia.pdf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for folder_name in myfolders:\n",
    "\n",
    "    ## unzip and gather only the pdf files\n",
    "    with ZipFile(folder_name, 'r') as my_folder_object:\n",
    "      file_names_list = my_folder_object.namelist()\n",
    "      ## iterate over the file names\n",
    "      for file_name in file_names_list:\n",
    "        if file_name.endswith('.pdf'):\n",
    "            my_folder_object.extract(file_name, \"pdfs\")\n",
    "            print(f\"Found this image: {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here you should physically deleted ```homework_fuds/alaska_fuds/USACE 2018_FUDS_Inventory_Alaska.pdf```\n",
    "\n",
    "#### otherwise the Alaska file is causing some problems because of its layout (address is much longer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homework-for-week-9_BLANKS.ipynb     homework_fuds.zip\r\n",
      "homework-for-week-9_SOLUTIONS.ipynb  \u001b[1m\u001b[36mpdfs\u001b[m\u001b[m/\r\n",
      "\u001b[1m\u001b[36mhomework_fuds\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pdfs/ny_fuds/FUDS_NY.pdf',\n",
       " 'pdfs/west_virginia_fuds/FUDS_Inventory_WestVirginia.pdf']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## gather all pdfs in a list\n",
    "myfiles = sorted(glob.glob('pdfs/*/*.pdf'))\n",
    "myfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## write function to combine tabula tables into a single csv\n",
    "def combine_tables(list_name,filename):\n",
    "  '''\n",
    "  Takes tables produced by tabula and combines into a single CSV\n",
    "  CSV extension needed!\n",
    "  Arguments: name of list produced by tabula and the CSV name you want (in quotes as a string)\n",
    "  '''\n",
    "  dataframes = [pd.DataFrame(a_table) for a_table in list_name] ## list comprehension to turn each tabula table into a dataframe\n",
    "  df = pd.concat(dataframes) ## join/concat all the dataframes into one dataframe\n",
    "  df.reset_index(inplace = True, drop = True) ## reset index, drop what was there before\n",
    "  df.to_csv(filename, encoding='utf-8', index=False) ## convert that single dataframe into a csv\n",
    "#   files.download(filename) ## download it COLAB ONLY!\n",
    "  print(f\"{filename} is in your downloads folder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdfs/ny_fuds/FUDS_NY.pdf\n",
      "<class 'list'>\n",
      "table_1.csv is in your downloads folder!\n",
      "pdfs/west_virginia_fuds/FUDS_Inventory_WestVirginia.pdf\n",
      "<class 'list'>\n",
      "table_2.csv is in your downloads folder!\n"
     ]
    }
   ],
   "source": [
    "### export each pdf as a table\n",
    "counter = 1\n",
    "for file in myfiles:\n",
    "    print(file)\n",
    "    ## get all the pages\n",
    "    contribs_tables = tabula.read_pdf(file, pages = \"all\")\n",
    "    print(type(contribs_tables))\n",
    "    combine_tables(contribs_tables, f\"table_{counter}.csv\")  ## using function\n",
    "    counter+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['table_2.csv', 'table_1.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### gather all csv files as a list\n",
    "all_filenames = [a_file for a_file in glob.glob('*.csv')]\n",
    "all_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(a_csv_file) for a_csv_file in all_filenames ])\n",
    "#export to csv\n",
    "combined_csv.to_csv( \"combined_csv.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "APAC homework-for-week-9 Scan tables in PDFs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
