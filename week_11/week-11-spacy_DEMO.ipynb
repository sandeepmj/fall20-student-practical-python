{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QwY_aPURcTp",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The problem?\n",
    "\n",
    "- Endless amounts of unstructured data found in emails, tweets, letters, memos, etc.\n",
    "- Even in transcripts\n",
    "- How can we make sense of all this data?\n",
    "- How can we 'easily' find relevant information for our reporting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The solution?\n",
    "- Computer programming to process all that text using **natural language processing**!\n",
    "- <a href=\"https://machinelearningmastery.com/natural-language-processing/\">Learn more</a> about the complexity and the history of NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Journalism examples\n",
    "\n",
    "- <a href=\"http://doctors.ajc.com/part_1_license_to_betray/\">License to betray</a> – Finding word stems and roots to uncover abuse.\n",
    "- <a href=\"https://www.revealnews.org/article/federal-judges-rulings-favored-companies-in-which-he-owned-stock/\">Federal judge’s rulings favored companies in which he owned stock</a> – Finding all stock owned by judges in disclosure forms and comparing to caseloads.\n",
    "- <a href=\"https://www.latimes.com/local/cityhall/la-me-crime-stats-20151015-story.html\">LAPD underreported serious assaults, skewing crime stats for 8 years</a> – Text classification analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The tools\n",
    "\n",
    "- Spacy v. NLTK\n",
    "- NLTK launched in 2001, Spacy in 2015\n",
    "- NLTK is now bloated and complex, requiring many steps to deal with many changes etc.\n",
    "- Spacy is lean and modern, and can compute some text 4x to 20x faster than NLTK.\n",
    "- Spacy does **nearly** everything that NLTK does, but better.\n",
    "- NLTK, however, is still the library of choice for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Working with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ly8WKOVPYV9-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 1. Install Spacy\n",
    "\n",
    "If this first time ever using spacy on this computer, you must first do either the ```!conda install``` or ```!pip install```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oBpamsrWRcTr",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Conda install or...\n",
    "# !conda install -c conda-forge spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9947,
     "status": "ok",
     "timestamp": 1605068927258,
     "user": {
      "displayName": "Sandeep Junnarkar",
      "photoUrl": "",
      "userId": "15658885848901522782"
     },
     "user_tz": 300
    },
    "id": "a-S6NorkRcTu",
    "outputId": "4307f275-5b08-45d2-b94c-273cdd5554dd",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: spacy in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (2.3.2)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied, skipping upgrade: thinc==7.4.1 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy) (7.4.1)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy) (4.47.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy) (49.2.0.post20200714)\n",
      "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XdUvDJNDRcTy",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## import libary.\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8xpwtwPRcT1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Troubleshoot here if problems with setup:\n",
    "https://github.com/explosion/spacy-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KcPisnnlRcT1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 2. Install language model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7336,
     "status": "ok",
     "timestamp": 1605069048515,
     "user": {
      "displayName": "Sandeep Junnarkar",
      "photoUrl": "",
      "userId": "15658885848901522782"
     },
     "user_tz": 300
    },
    "id": "9L770hGkZePT",
    "outputId": "4815be5b-47c2-493a-b4e8-db38883fc16b",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from en_core_web_sm==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: setuptools in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (49.2.0.post20200714)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.18.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.47.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVP20HngRcT8"
   },
   "source": [
    "### Place English libary into a ```nlp``` pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pqDMPPHxRcT8",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## build nlp pipeline (a function will tokenize, parse and ner for us)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1605069097627,
     "user": {
      "displayName": "Sandeep Junnarkar",
      "photoUrl": "",
      "userId": "15658885848901522782"
     },
     "user_tz": 300
    },
    "id": "R0G92vbFFFlU",
    "outputId": "f6a96803-3e31-433f-bfa0-fa9c6a63e045",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## what type of object is nlp\n",
    "type(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 3. Text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "yy8E66pRRcT5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### Sampel English text:\n",
    "text = u'''\\\n",
    "On May 10, 2011, Microsoft announced its acquisition of Skype Technologies, \\\n",
    "creator of the VoIP service Skype, for $8.5 billion. \\\n",
    "Microsoft is headquartered near Seattle Washington while Skype remains in Palo Alto, California. \\\n",
    "Sandeep Junnarkar got this from Wikipedia. \\\n",
    "But he'd rather head to Paris, France to see the Mona Lisa at the Louvre. \\\n",
    "Mount Washington, which is really Agiocochook, is the highest peak in the Northeastern United States \\\n",
    "at 6,288.2 ft and the most topographically prominent mountain east \\\n",
    "of the Mississippi River. It's not in Mississippi.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZQdKpPKRcT_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tokenize our text\n",
    "\n",
    "- Tokenizing is always the first step in text analysis. \n",
    "- It breaks all text into isolated but related units (including spaces, symbols, punctuation, numbers, words etc.)\n",
    "- However, it retains the connection between all the words, sentences, and paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "SHeDiZnRRcUA",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## let's run the nlp function and create a spacy doc\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1605069248572,
     "user": {
      "displayName": "Sandeep Junnarkar",
      "photoUrl": "",
      "userId": "15658885848901522782"
     },
     "user_tz": 300
    },
    "id": "y1aV38l6RcUC",
    "outputId": "bbbf5311-29a2-4ed6-df76-42d4df1142e6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## what type of data is it?\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9zJ_bNTzRcUF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On\n",
      "May\n",
      "10\n",
      ",\n",
      "2011\n",
      ",\n",
      "Microsoft\n",
      "announced\n",
      "its\n",
      "acquisition\n",
      "of\n",
      " \n",
      "Skype\n",
      "Technologies\n",
      ",\n",
      "creator\n",
      "of\n",
      "the\n",
      " \n",
      "VoIP\n",
      " \n",
      "service\n",
      " \n",
      "Skype\n",
      ",\n",
      "for\n",
      "$\n",
      "8.5\n",
      "billion\n",
      ".\n",
      "Microsoft\n",
      "is\n",
      "headquartered\n",
      "near\n",
      "Seattle\n",
      "Washington\n",
      "while\n",
      "Skype\n",
      "remains\n",
      "in\n",
      "Palo\n",
      "Alto\n",
      ",\n",
      "California\n",
      ".\n",
      "Sandeep\n",
      "Junnarkar\n",
      "got\n",
      "this\n",
      "from\n",
      "Wikipedia\n",
      ".\n",
      "But\n",
      "he\n",
      "'d\n",
      "rather\n",
      "head\n",
      "to\n",
      "Paris\n",
      ",\n",
      "France\n",
      "to\n",
      "see\n",
      "the\n",
      "Mona\n",
      "Lisa\n",
      "at\n",
      "the\n",
      "Louvre\n",
      ".\n",
      "Mount\n",
      "Washington\n",
      ",\n",
      "which\n",
      "is\n",
      "really\n",
      "Agiocochook\n",
      ",\n",
      "is\n",
      "the\n",
      "highest\n",
      "peak\n",
      "in\n",
      "the\n",
      "Northeastern\n",
      "United\n",
      "States\n",
      "at\n",
      "6,288.2\n",
      "ft\n",
      "and\n",
      "the\n",
      "most\n",
      "topographically\n",
      "prominent\n",
      "mountain\n",
      "east\n",
      "of\n",
      "the\n",
      "Mississippi\n",
      "River\n",
      ".\n",
      "It\n",
      "'s\n",
      "not\n",
      "in\n",
      "Mississippi\n",
      ".\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## show each token\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stop Words\n",
    "\n",
    "- These are common words that add no additional meaning to our analysis.\n",
    "- Words like ```the```, ```and``` and ```any```.\n",
    "- Spacy has just over 320 ```stop words``` in its defalt library.\n",
    "- Read more on <a href=\"https://medium.com/@saitejaponugoti/stop-words-in-nlp-5b248dadad47\">stop words</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'of', 'such', 'might', 'sixty', 'its', 'third', 'yourself', 'former', 'however', 'others', 'ever', 'top', 'because', \"'ll\", 'upon', 'used', 'he', 'less', 'behind', 'ca', 'anyway', 'serious', 'everything', 'i', '‘ve', \"'s\", '‘ll', 'how', 'keep', 'us', '‘m', 'her', '’m', 'themselves', 'seems', 'beyond', 'whereas', 'had', \"'m\", \"'ve\", 'formerly', 'somewhere', 'too', 'this', '’re', 'his', 'since', 'move', 'within', 'do', 'still', 'doing', 'cannot', 'am', 'using', 'beside', 'be', 'must', 'about', 'me', 'whoever', 'only', 'off', 'whole', '’ll', '’ve', 'in', 'hundred', 'whereupon', 'get', 'ourselves', 'himself', 'five', 'further', 'has', 'fifty', 'noone', 'latter', 'back', 'as', 'whose', 'here', 'did', 'many', 'eleven', 'during', 'through', 'these', 'who', 'hereupon', 'regarding', 'via', 'any', 'until', 'besides', 'a', 'on', 'thus', 'hereby', 'four', 'throughout', 'last', 'together', '’s', 'take', 'so', 'either', 'alone', 'may', 'and', 'whenever', 'among', 'make', 'for', 'becomes', 'nine', 'now', 'often', 'hers', 'put', 'part', 'well', 'n‘t', 'perhaps', 'just', 'across', 'bottom', 'becoming', 'other', 'then', 'seemed', 'they', 'mostly', 'you', 'twelve', 'nobody', 'why', 'amongst', 'no', 'it', 'have', 'ours', 'not', 'thereupon', 'enough', 'three', 'the', 'once', 'therein', 'few', 'namely', 'never', 'first', 'almost', 'before', 'n’t', 'neither', 'amount', 'where', 'due', 'along', 'please', 'twenty', 'an', 'each', 'my', 'hereafter', 'down', 'every', 'name', 'also', 'nowhere', 'them', 'full', 'to', 'whatever', 'were', '’d', 'was', 'mine', 'made', 'than', 'all', 'per', 'much', 'most', 'does', 'at', 'one', 'otherwise', 'hence', 'beforehand', 'should', 'thereafter', 'whom', 'say', 'those', \"'d\", 'forty', 'onto', 'yet', 'anyone', 'elsewhere', 'done', 'our', \"'re\", 'call', 'wherein', 'least', 'could', 'out', 'see', 'side', 'yours', 'she', 'herein', 'which', '‘s', 'will', 'itself', 'if', 'thru', 'some', '‘d', 'without', 're', 'being', 'under', 'indeed', 'another', 'while', 'can', 'someone', '‘re', 'their', 'empty', 'from', 'there', 'moreover', 'none', 'thence', 'when', 'whether', 'afterwards', 'thereby', 'somehow', 'though', 'above', 'with', 'anyhow', 'give', 'that', 'again', 'quite', 'whereafter', 'nor', 'unless', 'nothing', 'everyone', 'whereby', 'six', 'both', 'front', 'him', 'over', 'except', 'always', 'into', 'herself', 'by', 'eight', 'wherever', 'sometimes', 'various', 'we', 'seeming', 'sometime', 'is', 'meanwhile', 'latterly', \"n't\", 'anything', 'more', 'towards', 'whence', 'next', 'therefore', 'became', 'been', 'after', 'up', 'below', 'show', 'something', 'what', 'two', 'myself', 'ten', 'very', 'but', 'fifteen', 'nevertheless', 'your', 'anywhere', 'own', 'become', 'although', 'or', 'several', 'else', 'same', 'between', 'even', 'really', 'rather', 'would', 'already', 'whither', 'seem', 'around', 'are', 'yourselves', 'everywhere', 'toward', 'go', 'against'}\n"
     ]
    }
   ],
   "source": [
    "## show all default stop words\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check if a word (have, near, be) is a stop word \n",
    "nlp.vocab[\"have\"].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## how many do stop words do we have?\n",
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Add your own stop word\n",
    "nlp.Defaults.stop_words.add(\"lol\")\n",
    "nlp.vocab[\"lol\"].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CHECK IF 'lol' is a stop word\n",
    "nlp.vocab['lol'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## how many do stop words do we have now?\n",
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Remove a stop word from list because it is relevant.\n",
    "## notice the word \"empty\" is a stop word.\n",
    "# nlp.vocab['empty'].is_stop\n",
    "nlp.Defaults.stop_words.remove(\"empty\")\n",
    "nlp.vocab[\"empty\"].is_stop = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CHECK IF 'empty' is a stop word\n",
    "nlp.vocab[\"empty\"].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts of speech\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On                      85 ADP  \n",
      "May                     96 PROPN\n",
      "10                      93 NUM  \n",
      ",                       97 PUNCT\n",
      "2011                    93 NUM  \n",
      ",                       97 PUNCT\n",
      "Microsoft               96 PROPN\n",
      "announced              100 VERB \n",
      "its                     90 DET  \n",
      "acquisition             92 NOUN \n",
      "of                      85 ADP  \n",
      "                       103 SPACE\n",
      "Skype                   96 PROPN\n",
      "Technologies            96 PROPN\n",
      ",                       97 PUNCT\n",
      "creator                 92 NOUN \n",
      "of                      85 ADP  \n",
      "the                     90 DET  \n",
      "                       103 SPACE\n",
      "VoIP                    92 NOUN \n",
      "                       103 SPACE\n",
      "service                 92 NOUN \n",
      "                       103 SPACE\n",
      "Skype                   96 PROPN\n",
      ",                       97 PUNCT\n",
      "for                     85 ADP  \n",
      "$                       99 SYM  \n",
      "8.5                     93 NUM  \n",
      "billion                 93 NUM  \n",
      ".                       97 PUNCT\n",
      "Microsoft               96 PROPN\n",
      "is                      87 AUX  \n",
      "headquartered          100 VERB \n",
      "near                    98 SCONJ\n",
      "Seattle                 96 PROPN\n",
      "Washington              96 PROPN\n",
      "while                   98 SCONJ\n",
      "Skype                   96 PROPN\n",
      "remains                100 VERB \n",
      "in                      85 ADP  \n",
      "Palo                    96 PROPN\n",
      "Alto                    96 PROPN\n",
      ",                       97 PUNCT\n",
      "California              96 PROPN\n",
      ".                       97 PUNCT\n",
      "Sandeep                 96 PROPN\n",
      "Junnarkar               96 PROPN\n",
      "got                    100 VERB \n",
      "this                    90 DET  \n",
      "from                    85 ADP  \n",
      "Wikipedia               96 PROPN\n",
      ".                       97 PUNCT\n",
      "But                     89 CCONJ\n",
      "he                      95 PRON \n",
      "'d                     100 VERB \n",
      "rather                  86 ADV  \n",
      "head                   100 VERB \n",
      "to                      85 ADP  \n",
      "Paris                   96 PROPN\n",
      ",                       97 PUNCT\n",
      "France                  96 PROPN\n",
      "to                      94 PART \n",
      "see                    100 VERB \n",
      "the                     90 DET  \n",
      "Mona                    96 PROPN\n",
      "Lisa                    96 PROPN\n",
      "at                      85 ADP  \n",
      "the                     90 DET  \n",
      "Louvre                  96 PROPN\n",
      ".                       97 PUNCT\n",
      "Mount                   96 PROPN\n",
      "Washington              96 PROPN\n",
      ",                       97 PUNCT\n",
      "which                   90 DET  \n",
      "is                      87 AUX  \n",
      "really                  86 ADV  \n",
      "Agiocochook             96 PROPN\n",
      ",                       97 PUNCT\n",
      "is                      87 AUX  \n",
      "the                     90 DET  \n",
      "highest                 84 ADJ  \n",
      "peak                    92 NOUN \n",
      "in                      85 ADP  \n",
      "the                     90 DET  \n",
      "Northeastern            96 PROPN\n",
      "United                  96 PROPN\n",
      "States                  96 PROPN\n",
      "at                      85 ADP  \n",
      "6,288.2                 93 NUM  \n",
      "ft                      92 NOUN \n",
      "and                     89 CCONJ\n",
      "the                     90 DET  \n",
      "most                    86 ADV  \n",
      "topographically         86 ADV  \n",
      "prominent               84 ADJ  \n",
      "mountain                92 NOUN \n",
      "east                    86 ADV  \n",
      "of                      85 ADP  \n",
      "the                     90 DET  \n",
      "Mississippi             96 PROPN\n",
      "River                   96 PROPN\n",
      ".                       97 PUNCT\n",
      "It                      95 PRON \n",
      "'s                      87 AUX  \n",
      "not                     94 PART \n",
      "in                      85 ADP  \n",
      "Mississippi             96 PROPN\n",
      ".                       97 PUNCT\n",
      "\n",
      "                      103 SPACE\n"
     ]
    }
   ],
   "source": [
    "## print all parts of speech words\n",
    "for token in doc:\n",
    "    print(f\"{token.text:{15}} {token.pos:{10}} {token.pos_:{5}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 4. Named Entity Recognition (NER)\n",
    "\n",
    "#### Spacy easily returns the words that matter to us like names of companies, people, places, art works, numbers, etc.\n",
    "\n",
    "- ```.ents``` ------------> Finds all entities in doc spacy object.\n",
    "\n",
    "- ```ent.text``` ------------> The actual text.\n",
    "\n",
    "- ```ent.label``` ------------> A numeric code for the entity.\n",
    "\n",
    "- ```ent.label_``` ------------> The word's entity category.\n",
    "\n",
    "- ```spacy.explain(ent.label_)``` ---------> A description of the category.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute or relative dates or periods\n",
      "Companies, agencies, institutions, etc.\n",
      "Companies, agencies, institutions, etc.\n",
      "Objects, vehicles, foods, etc. (not services)\n",
      "Companies, agencies, institutions, etc.\n",
      "Monetary values, including unit\n",
      "Companies, agencies, institutions, etc.\n",
      "Countries, cities, states\n",
      "Countries, cities, states\n",
      "Companies, agencies, institutions, etc.\n",
      "Countries, cities, states\n",
      "Countries, cities, states\n",
      "People, including fictional\n",
      "Countries, cities, states\n",
      "Countries, cities, states\n",
      "Titles of books, songs, etc.\n",
      "Non-GPE locations, mountain ranges, bodies of water\n",
      "People, including fictional\n",
      "Non-GPE locations, mountain ranges, bodies of water\n",
      "Measurements, as of weight or distance\n",
      "Non-GPE locations, mountain ranges, bodies of water\n",
      "Non-GPE locations, mountain ranges, bodies of water\n",
      "Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "## find all entities\n",
    "\n",
    "for word in doc.ents:\n",
    "    print(spacy.explain(word.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May 10, 2011 ---->DATE\n",
      "Microsoft ---->ORG\n",
      "Skype Technologies ---->ORG\n",
      "VoIP  ---->PRODUCT\n",
      "Skype ---->ORG\n",
      "$8.5 billion ---->MONEY\n",
      "Microsoft ---->ORG\n",
      "Seattle ---->GPE\n",
      "Washington ---->GPE\n",
      "Skype ---->ORG\n",
      "Palo Alto ---->GPE\n",
      "California ---->GPE\n",
      "Sandeep Junnarkar ---->PERSON\n",
      "Paris ---->GPE\n",
      "France ---->GPE\n",
      "the Mona Lisa ---->WORK_OF_ART\n",
      "Mount Washington ---->LOC\n",
      "Agiocochook ---->PERSON\n",
      "the Northeastern United States ---->LOC\n",
      "6,288.2 ft ---->QUANTITY\n",
      "mountain east ---->LOC\n",
      "the Mississippi River ---->LOC\n",
      "Mississippi ---->GPE\n"
     ]
    }
   ],
   "source": [
    "## find all entities with their label\n",
    "for word in doc.ents:\n",
    "    print(f\"{word.text} ---->{word.label_}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May 10, 2011 ---->391 ----->DATE ---->Absolute or relative dates or periods\n",
      "Microsoft ---->383 ----->ORG ---->Companies, agencies, institutions, etc.\n",
      "Skype Technologies ---->383 ----->ORG ---->Companies, agencies, institutions, etc.\n",
      "VoIP  ---->386 ----->PRODUCT ---->Objects, vehicles, foods, etc. (not services)\n",
      "Skype ---->383 ----->ORG ---->Companies, agencies, institutions, etc.\n",
      "$8.5 billion ---->394 ----->MONEY ---->Monetary values, including unit\n",
      "Microsoft ---->383 ----->ORG ---->Companies, agencies, institutions, etc.\n",
      "Seattle ---->384 ----->GPE ---->Countries, cities, states\n",
      "Washington ---->384 ----->GPE ---->Countries, cities, states\n",
      "Skype ---->383 ----->ORG ---->Companies, agencies, institutions, etc.\n",
      "Palo Alto ---->384 ----->GPE ---->Countries, cities, states\n",
      "California ---->384 ----->GPE ---->Countries, cities, states\n",
      "Sandeep Junnarkar ---->380 ----->PERSON ---->People, including fictional\n",
      "Paris ---->384 ----->GPE ---->Countries, cities, states\n",
      "France ---->384 ----->GPE ---->Countries, cities, states\n",
      "the Mona Lisa ---->388 ----->WORK_OF_ART ---->Titles of books, songs, etc.\n",
      "Mount Washington ---->385 ----->LOC ---->Non-GPE locations, mountain ranges, bodies of water\n",
      "Agiocochook ---->380 ----->PERSON ---->People, including fictional\n",
      "the Northeastern United States ---->385 ----->LOC ---->Non-GPE locations, mountain ranges, bodies of water\n",
      "6,288.2 ft ---->395 ----->QUANTITY ---->Measurements, as of weight or distance\n",
      "mountain east ---->385 ----->LOC ---->Non-GPE locations, mountain ranges, bodies of water\n",
      "the Mississippi River ---->385 ----->LOC ---->Non-GPE locations, mountain ranges, bodies of water\n",
      "Mississippi ---->384 ----->GPE ---->Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "## find all entities with their label and label descriptors\n",
    "for word in doc.ents:\n",
    "    print(f\"{word.text} ---->{word.label} ----->{word.label_} ---->{spacy.explain(word.label_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a CSV that holds all the organizations/companies in a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find all entities and place in a list using list comprehension\n",
    "entities = [word.text for word in doc.ents]\n",
    "ent_labels = [word.label_ for word in doc.ents]\n",
    "\n",
    "# entities = []\n",
    "# for word in doc.ents:\n",
    "#     entities.append(word.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['May 10, 2011', 'Microsoft', 'Skype Technologies', 'VoIP\\xa0', 'Skype', '$8.5 billion', 'Microsoft', 'Seattle', 'Washington', 'Skype', 'Palo Alto', 'California', 'Sandeep Junnarkar', 'Paris', 'France', 'the Mona Lisa', 'Mount Washington', 'Agiocochook', 'the Northeastern United States', '6,288.2 ft', 'mountain east', 'the Mississippi River', 'Mississippi']\n",
      "['DATE', 'ORG', 'ORG', 'PRODUCT', 'ORG', 'MONEY', 'ORG', 'GPE', 'GPE', 'ORG', 'GPE', 'GPE', 'PERSON', 'GPE', 'GPE', 'WORK_OF_ART', 'LOC', 'PERSON', 'LOC', 'QUANTITY', 'LOC', 'LOC', 'GPE']\n"
     ]
    }
   ],
   "source": [
    "print(entities)\n",
    "print(ent_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'DATE': 'May 10, 2011'},\n",
       " {'ORG': 'Microsoft'},\n",
       " {'ORG': 'Skype Technologies'},\n",
       " {'PRODUCT': 'VoIP\\xa0'},\n",
       " {'ORG': 'Skype'},\n",
       " {'MONEY': '$8.5 billion'},\n",
       " {'ORG': 'Microsoft'},\n",
       " {'GPE': 'Seattle'},\n",
       " {'GPE': 'Washington'},\n",
       " {'ORG': 'Skype'},\n",
       " {'GPE': 'Palo Alto'},\n",
       " {'GPE': 'California'},\n",
       " {'PERSON': 'Sandeep Junnarkar'},\n",
       " {'GPE': 'Paris'},\n",
       " {'GPE': 'France'},\n",
       " {'WORK_OF_ART': 'the Mona Lisa'},\n",
       " {'LOC': 'Mount Washington'},\n",
       " {'PERSON': 'Agiocochook'},\n",
       " {'LOC': 'the Northeastern United States'},\n",
       " {'QUANTITY': '6,288.2 ft'},\n",
       " {'LOC': 'mountain east'},\n",
       " {'LOC': 'the Mississippi River'},\n",
       " {'GPE': 'Mississippi'}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Turn the two lists into a dictionary using a for loop\n",
    "my_entities_fl = []\n",
    "for (key, value) in zip(ent_labels, entities):\n",
    "    mydict = {key: value}\n",
    "    my_entities_fl.append(mydict)\n",
    "\n",
    "my_entities_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'DATE': 'May 10, 2011'},\n",
       " {'ORG': 'Microsoft'},\n",
       " {'ORG': 'Skype Technologies'},\n",
       " {'PRODUCT': 'VoIP\\xa0'},\n",
       " {'ORG': 'Skype'},\n",
       " {'MONEY': '$8.5 billion'},\n",
       " {'ORG': 'Microsoft'},\n",
       " {'GPE': 'Seattle'},\n",
       " {'GPE': 'Washington'},\n",
       " {'ORG': 'Skype'},\n",
       " {'GPE': 'Palo Alto'},\n",
       " {'GPE': 'California'},\n",
       " {'PERSON': 'Sandeep Junnarkar'},\n",
       " {'GPE': 'Paris'},\n",
       " {'GPE': 'France'},\n",
       " {'WORK_OF_ART': 'the Mona Lisa'},\n",
       " {'LOC': 'Mount Washington'},\n",
       " {'PERSON': 'Agiocochook'},\n",
       " {'LOC': 'the Northeastern United States'},\n",
       " {'QUANTITY': '6,288.2 ft'},\n",
       " {'LOC': 'mountain east'},\n",
       " {'LOC': 'the Mississippi River'},\n",
       " {'GPE': 'Mississippi'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Turn the two lists into a dictionary using a list comprehension\n",
    "my_entities = [{key: value} for (key, value) in zip(ent_labels, entities)]\n",
    "my_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ORG': 'Microsoft'},\n",
       " {'ORG': 'Skype Technologies'},\n",
       " {'ORG': 'Skype'},\n",
       " {'ORG': 'Microsoft'},\n",
       " {'ORG': 'Skype'}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the previous lists hold all entities. \n",
    "## let's narrow them down to the orgs/companies\n",
    "all_orgs = [{key: value} for (key, value) in zip(ent_labels, entities) if key == \"ORG\"]\n",
    "all_orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "## What data types are these?\n",
    "for thing in all_orgs:\n",
    "    for key, value in thing.items():\n",
    "        print(f\"{type(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's make sure all the key and value pairs are strings \n",
    "## instead of spacy objects so we can move them into a df and csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## confirm key, value are both strings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ORG': 'Microsoft'}, {'ORG': 'Skype Technologies'}, {'ORG': 'Skype'}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## deduplicate a dictionary\n",
    "orgs_only = {frozenset(item.items()) : item for item in all_orgs}.values()\n",
    "list(orgs_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_entities.csv is in your project folder!\n"
     ]
    }
   ],
   "source": [
    "# ## use pandas to write to csv file\n",
    "filename = \"test_entities.csv\"\n",
    "df = pd.DataFrame(orgs_only) ## we turn our life dict into a dataframe which we're call df\n",
    "df.to_csv(filename, encoding='utf-8', index=False)\n",
    "\n",
    "print(f\"{filename} is in your project folder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "R_aeW2aMRcUK",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## function to find entities\n",
    "def show_entities(my_text):\n",
    "    each_token = \"Token\"\n",
    "    entity_type = \"Entity\"\n",
    "    entity_def = \"Entity Defined\"\n",
    "    print(f\"{each_token:{30}}{entity_type:{15}}{entity_def}\")\n",
    "    if my_text.ents:\n",
    "        for word in doc.ents:\n",
    "            print(f\"{word.text:{30}} {word.label_:{15}} {str(spacy.explain(word.label_))}\")\n",
    "    else:\n",
    "        print(\"There are no entities in this text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '2011', 'Microsoft', 'announced', 'acquisition', ' ', 'Skype', 'Technologies', 'creator', ' ', 'VoIP', ' ', 'service', ' ', 'Skype', '$', '8.5', 'billion', 'Microsoft', 'headquartered', 'near', 'Seattle', 'Washington', 'Skype', 'remains', 'Palo', 'Alto', 'California', 'Sandeep', 'Junnarkar', 'got', 'Wikipedia', 'head', 'Paris', 'France', 'Mona', 'Lisa', 'Louvre', 'Mount', 'Washington', 'Agiocochook', 'highest', 'peak', 'Northeastern', 'United', 'States', '6,288.2', 'ft', 'topographically', 'prominent', 'mountain', 'east', 'Mississippi', 'River', 'Mississippi', '\\n']\n"
     ]
    }
   ],
   "source": [
    "words = [token.text.replace(u'\\xa0', ' ') for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1605069904247,
     "user": {
      "displayName": "Sandeep Junnarkar",
      "photoUrl": "",
      "userId": "15658885848901522782"
     },
     "user_tz": 300
    },
    "id": "oTNWHsd_RxW9",
    "outputId": "b74688d0-6dd8-4078-d242-161c962139b7",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token                         Entity         Entity Defined\n",
      "May 10, 2011                   DATE            Absolute or relative dates or periods\n",
      "Microsoft                      ORG             Companies, agencies, institutions, etc.\n",
      "Skype Technologies             ORG             Companies, agencies, institutions, etc.\n",
      "VoIP                           PRODUCT         Objects, vehicles, foods, etc. (not services)\n",
      "Skype                          ORG             Companies, agencies, institutions, etc.\n",
      "$8.5 billion                   MONEY           Monetary values, including unit\n",
      "Microsoft                      ORG             Companies, agencies, institutions, etc.\n",
      "Seattle                        GPE             Countries, cities, states\n",
      "Washington                     GPE             Countries, cities, states\n",
      "Skype                          ORG             Companies, agencies, institutions, etc.\n",
      "Palo Alto                      GPE             Countries, cities, states\n",
      "California                     GPE             Countries, cities, states\n",
      "Sandeep Junnarkar              PERSON          People, including fictional\n",
      "Paris                          GPE             Countries, cities, states\n",
      "France                         GPE             Countries, cities, states\n",
      "the Mona Lisa                  WORK_OF_ART     Titles of books, songs, etc.\n",
      "Mount Washington               LOC             Non-GPE locations, mountain ranges, bodies of water\n",
      "Agiocochook                    PERSON          People, including fictional\n",
      "the Northeastern United States LOC             Non-GPE locations, mountain ranges, bodies of water\n",
      "6,288.2 ft                     QUANTITY        Measurements, as of weight or distance\n",
      "mountain east                  LOC             Non-GPE locations, mountain ranges, bodies of water\n",
      "the Mississippi River          LOC             Non-GPE locations, mountain ranges, bodies of water\n",
      "Mississippi                    GPE             Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "## show entities in my english sentence\n",
    "show_entities(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Skype', 3), ('Microsoft', 2), ('Washington', 2), ('Mississippi', 2), ('10', 1), ('2011', 1), ('announced', 1), ('acquisition', 1), ('Technologies', 1), ('creator', 1), ('VoIP', 1), ('service', 1), ('$', 1), ('8.5', 1), ('billion', 1), ('headquartered', 1), ('near', 1), ('Seattle', 1), ('remains', 1), ('Palo', 1), ('Alto', 1), ('California', 1), ('Sandeep', 1), ('Junnarkar', 1), ('got', 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter  ## a package that helps us count up frequency\n",
    "## Counter(some_variable)\n",
    "## variable_name.most.common(some_number)\n",
    "\n",
    "#remove stopwords and punctuations\n",
    "words = [token.text for token in doc if token.is_stop != True and token.is_punct != True and token.text != '\\xa0']\n",
    "word_freq = Counter(words)\n",
    "common_words = word_freq.most_common(25)  ## use most.common()\n",
    "print (common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nkzIHWcRcUM",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Install other languages\n",
    "#### Other languages can be found at https://spacy.io/usage/models\n",
    "\n",
    "#### Disclaimer: Language models are built by open source communities. English and German are the most advanced language models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QC8HluMERcUN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Spanish language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "SuHEEuUDSXPa",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: es_core_news_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.3.1/es_core_news_sm-2.3.1.tar.gz#egg=es_core_news_sm==2.3.1 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from es_core_news_sm==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: thinc==7.4.1 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: setuptools in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (49.2.0.post20200714)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (1.18.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (4.47.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sandeep.junnarkar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->es_core_news_sm==2.3.1) (2020.6.20)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "## !python install the library\n",
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "qmjeb7LYRcUQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## import the library and create nlp pipleline\n",
    "import es_core_news_sm\n",
    "nlp = es_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "XEfgJHvERcUW",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### Sample Spanish Text (sorry!)\n",
    "stext = \"\"\"\n",
    "El 10 de mayo de 2011, Microsoft anunció la adquisición de Skype Technologies, \\\n",
    "creador del servicio de VoIP Skype, por $ 8.5 mil millones. \\\n",
    "Microsoft tiene su sede cerca de Seattle Washington, mientras que Skype permanece en Palo Alto, California. \\\n",
    "Sandeep Junnarkar obtuvo esto de Wikipedia. \\\n",
    "Pero preferiría ir a París, Francia, para ver la Mona Lisa en el Louvre. \\\n",
    "Mount Washington, que en realidad es Agiocochook, es el pico más alto del noreste de Estados Unidos.\n",
    "a 6.288,2 pies y la montaña más prominente topográficamente al este \\\n",
    "del río Mississippi.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "eg767ypnRcUY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## tokenize and show parts of speech for each token\n",
    "doc = nlp(stext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "dt67pTWYGmVf",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "El\n",
      "10\n",
      "de\n",
      "mayo\n",
      "de\n",
      "2011\n",
      ",\n",
      "Microsoft\n",
      "anunció\n",
      "la\n",
      "adquisición\n",
      "de\n",
      "Skype\n",
      "Technologies\n",
      ",\n",
      "creador\n",
      "del\n",
      "servicio\n",
      "de\n",
      "VoIP\n",
      "Skype\n",
      ",\n",
      "por\n",
      "$\n",
      "8.5\n",
      "mil\n",
      "millones\n",
      ".\n",
      "Microsoft\n",
      "tiene\n",
      "su\n",
      "sede\n",
      "cerca\n",
      "de\n",
      "Seattle\n",
      "Washington\n",
      ",\n",
      "mientras\n",
      "que\n",
      "Skype\n",
      "permanece\n",
      "en\n",
      "Palo\n",
      "Alto\n",
      ",\n",
      "California\n",
      ".\n",
      "Sandeep\n",
      "Junnarkar\n",
      "obtuvo\n",
      "esto\n",
      "de\n",
      "Wikipedia\n",
      ".\n",
      "Pero\n",
      "preferiría\n",
      "ir\n",
      "a\n",
      "París\n",
      ",\n",
      "Francia\n",
      ",\n",
      "para\n",
      "ver\n",
      "la\n",
      "Mona\n",
      "Lisa\n",
      "en\n",
      "el\n",
      "Louvre\n",
      ".\n",
      "Mount\n",
      "Washington\n",
      ",\n",
      "que\n",
      "en\n",
      "realidad\n",
      "es\n",
      "Agiocochook\n",
      ",\n",
      "es\n",
      "el\n",
      "pico\n",
      "más\n",
      "alto\n",
      "del\n",
      "noreste\n",
      "de\n",
      "Estados\n",
      "Unidos\n",
      ".\n",
      "\n",
      "\n",
      "a\n",
      "6.288,2\n",
      "pies\n",
      "y\n",
      "la\n",
      "montaña\n",
      "más\n",
      "prominente\n",
      "topográficamente\n",
      "al\n",
      "este\n",
      "del\n",
      "río\n",
      "Mississippi\n",
      ".\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## show the tokens\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "onKjJi8ORcUa",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token                         Entity         Entity Defined\n",
      "Microsoft                      ORG             Companies, agencies, institutions, etc.\n",
      "Skype Technologies             ORG             Companies, agencies, institutions, etc.\n",
      "VoIP Skype                     MISC            Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "Microsoft                      ORG             Companies, agencies, institutions, etc.\n",
      "Seattle Washington             LOC             Non-GPE locations, mountain ranges, bodies of water\n",
      "Skype                          MISC            Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "Palo Alto                      LOC             Non-GPE locations, mountain ranges, bodies of water\n",
      "California                     LOC             Non-GPE locations, mountain ranges, bodies of water\n",
      "Sandeep Junnarkar              LOC             Non-GPE locations, mountain ranges, bodies of water\n",
      "Wikipedia                      MISC            Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "Pero preferiría ir a París     MISC            Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "Francia                        LOC             Non-GPE locations, mountain ranges, bodies of water\n",
      "la Mona Lisa                   PER             Named person or family.\n",
      "Louvre                         LOC             Non-GPE locations, mountain ranges, bodies of water\n",
      "Mount Washington               PER             Named person or family.\n",
      "Agiocochook                    LOC             Non-GPE locations, mountain ranges, bodies of water\n",
      "Estados Unidos                 LOC             Non-GPE locations, mountain ranges, bodies of water\n",
      "Mississippi                    LOC             Non-GPE locations, mountain ranges, bodies of water\n"
     ]
    }
   ],
   "source": [
    "## show entities\n",
    "show_entities(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MSEF5iHleMY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Chinese language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20143,
     "status": "ok",
     "timestamp": 1605070302857,
     "user": {
      "displayName": "Sandeep Junnarkar",
      "photoUrl": "",
      "userId": "15658885848901522782"
     },
     "user_tz": 300
    },
    "id": "uLTao2Lmlgng",
    "outputId": "855c8c8b-7e3d-4075-a367-cb49cb7db4e2",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## !python install the library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNRPxSFDlr7J",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## import the library and create nlp pipleline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZw79PW1qzTc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### Sample Chinese Text (sorry!)\n",
    "ctext = '''\n",
    "2011年5月10日，微軟宣布收購Skype Technologies，\n",
    "VoIP服務的創造者，價格為85億美元。\n",
    "微軟總部位於華盛頓州西雅圖市附近，而Skype仍位於加利福尼亞州帕洛阿爾托。\\\n",
    "Sandeep Junnarkar從Wikipedia獲得了此信息。\\\n",
    "但他寧願前往法國巴黎在羅浮宮看《蒙娜麗莎》。\\\n",
    "華盛頓山（實際上是Agiocochook）是美國東北部的最高峰\\\n",
    "位於6,288.2英尺，是東面地形最突出的山脈\\\n",
    "密西西比河。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFzWDLcBpf8-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## create a spacy doc object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1605070781700,
     "user": {
      "displayName": "Sandeep Junnarkar",
      "photoUrl": "",
      "userId": "15658885848901522782"
     },
     "user_tz": 300
    },
    "id": "_RPV9T2irG3J",
    "outputId": "1129a713-98ef-4734-a2ff-2980c5f073a3",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## run our function!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [
    "fvkdsW79RcUN"
   ],
   "name": "APAC-week-15 spacy_SOLUTIONS.ipynb",
   "provenance": [
    {
     "file_id": "1NHGImT0kxlFki3ktI66ZfpZDEMhIr94T",
     "timestamp": 1605060862393
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
