{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Documents via Scrape from <a href=\"http://dof.ca.gov/Forecasting/Economics/Economic_and_Revenue_Updates/\">this site</a>\n",
    "\n",
    "```http://dof.ca.gov/Forecasting/Economics/Economic_and_Revenue_Updates/```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## url to scrape\n",
    "url = \"http://dof.ca.gov/Forecasting/Economics/Economic_and_Revenue_Updates/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get url and print but hard to read. will do prettify next\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gather all the div with class = \"quarter\"\n",
    "pdf_section = soup.find_all(\"ul\", class_=\"archive\")\n",
    "print(pdf_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check type\n",
    "print(type(pdf_section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gather each li in the class quarter using a for loop\n",
    "all_li_fl = []\n",
    "for each_section in pdf_section:\n",
    "    all_li_fl.append(each_section.find_all(\"li\"))\n",
    "\n",
    "    \n",
    "all_li_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## we do the same but in a list comprehension\n",
    "all_uls = [each_section.find_all(\"li\") for each_section in pdf_section]\n",
    "all_uls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notice how you have lists within a big list\n",
    "\n",
    "This will require you to run a for loop within a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## base url we'll need to add to partial url\n",
    "base_url = \"http://dof.ca.gov/Forecasting/Economics/Economic_and_Revenue_Updates/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "all_urls_it = [base_url + target.find(\"a\").get(\"href\")\\\n",
    "               for target in list(itertools.chain(*all_uls))]\n",
    "all_urls_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a for loop within a for loop to target the lists within the big list\n",
    "all_urls_fl = []\n",
    "for my_LIs in all_uls:\n",
    "    for myLi in my_LIs:\n",
    "        all_urls_fl.append(base_url+myLi.find(\"a\").get(\"href\"))\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "all_urls_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # time is required. we will use its sleep function\n",
    "from random import randrange # generate random numbers\n",
    "import wget # can put down documents, files from websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## download all PDFs\n",
    "links_number = len(all_urls_it)\n",
    "link_count = 1\n",
    "for link in all_urls_it:\n",
    "    print(f\"Downloaded link {link_count} of {links_number}\")\n",
    "    wget.download(link, \"\")\n",
    "    link_count += 1\n",
    "    snooze = randrange(3,6)\n",
    "    print(f\"snoozing for {snooze} seconds before scraping next link.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
